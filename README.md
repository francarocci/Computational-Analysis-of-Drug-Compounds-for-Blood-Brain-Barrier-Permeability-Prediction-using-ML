# Computational-Analysis-of-Drug-Compounds-for-Blood-Brain-Barrier-Permeability-Prediction-using-ML
Computational Analysis of Drug Compounds for Blood-Brain Barrier Permeability Prediction with ML techniques

# Introduction 

The development of drugs for the central nervous system (CNS) faces considerable hurdles due to the Blood-Brain Barrier (BBB), a protective mechanism that limits the entry of therapeutic compounds into the brain. Predicting which drugs can permeate the BBB is thus crucial, and computational models have emerged as a promising solution to aid the prediction. These models can analyse molecular descriptors which are quantitative metrics of a compound's chemical structure, to predict BBB permeability, focusing on key physicochemical characteristics such as lipophilicity, molecular size, and polar surface area, which are pivotal for BBB penetration (1, 2, 3). Such computational approaches are increasingly vital in drug discovery, particularly for CNS targets, aligning with recent advancements that emphasise the importance of early-stage computational techniques (4).

The study introduces a Python-based tool integrated with machine learning algorithms and a curated compound dataset to predict BBB permeability, aiming to streamline the CNS drug discovery process. This report details the tool's development and validation, highlighting its potential to expedite the identification of viable therapeutic agents for neurological conditions by efficiently navigating one of the significant barriers in CNS drug development.

# Methods 

Data Acquisition and Pre-processing

The BBB dataset, also called “BBB_dataset.xlsx” was successfully downloaded from a scientific study which aimed to classify the model for the penetration of the blood brain barrier (4). It was then imported to the Colab Notebooks virtual environment of Google Drive for computational analysis. 
Molecular descriptors, which have the function to differentiate the drug compounds into physical and chemical properties, were associated with the Simplified Molecular Input Line Entry (SMILES) notation of the chemical compounds that were listed on the BBB dataset. These two data components were concatenated into a single “molecular_descriptors.xlsx” file which was later transformed into a Panda DataFrame, which allowed for later analyses experimentation.

The dataset was loaded into a pandas DataFrame, concat_df, and its structure was examined using .info() and .describe() methods to ensure it was correctly concatenated. The descriptive statistical summary provided insights into the numerical features of the dataset, showing a range of values from minimum to maximum, as well as measures of central tendency and dispersion (mean, standard deviation) for each numerical column. Additionally, missing values were identified using isna() method chained with sum() to count occurrences column-wise. Rows containing any missing values were visualised by indexing the DataFrame where isna().any(axis=1) returned True. Three such instances were observed and subsequently removed using the dropna() method to maintain dataset integrity. The dataset was also inspected for duplicate entries using the duplicated().sum() method, however the output confirmed there were no duplicate rows in the dataset. The info() method was used again to confirm the cleaning process, with the updated memory usage reflecting the slightly reduced dataset size. Finally, a visual inspection was conducted to ensure data integrity post-cleaning, where the DataFrame was displayed to confirm that the appropriate rows were removed and to verify the structure of the cleaned dataset.

Exploratory Data Analysis

To explore the underlying structure of the dataset and identify patterns, several visual and statistical EDA methods were employed such as vertical count plot to detect the class distribution analysis and visualise the balance of the 'Class' column in the dataset, which represents drug permeability across the BBB, with classes 'BBB+' and 'BBB-'. The seaborn library was utilised to set an aesthetic style and produce the plot. The colours for each bar were manually set to improve visual distinction and both bars were annotated with the frequency count to provide immediate quantitative understanding.
Furthermore, Principal Component Analysis (PCA) was conducted to reduce the dimensionality of the dataset while preserving as much variability as possible. The scatter plot was created to visualise the first two principal components, coloured by the 'Class' of the drug (BBB permeable or not) and the percentage of variance explained by each principal component was indicated in the plot, providing insight into how much information was captured by the PCA.
To further test the dataset, the Recursive Feature Elimination (RFE) method was utilised to selected 10 most relevant features on the dataset based on a selection method that fits a model and removes the weakest features until the specified number of features is reached. This process assists in optimising the predictive models by reducing complexity and overfitting potential. This method was adopted by encoding the target variable with scikit-learn’s LabelEncoder() for ‘Class’ label, and then a Random Forest Classifier (RF) was initialised with 100 trees and a set random state for reproducibility.
Finally, the RFE model was serialised using pickle and saved to a file named 'rfe_model.pkl' allowing the model to be saved for future use without retraining.

Upon identifying the most relevant features for the dataset, further analysis was conducted to understand the relationships and distributions of these features. For instance, a subset of the DataFrame containing the top 10 features identified by RFE was created with the heatmap of the correlation matrix to assess the degree of linear relationship between each pair of features. Annotations were included to display the actual correlation coefficients and a green colour map was chosen to denote the strength and direction of correlations.
Moreover, a boxplot was created to visualise the distribution of the selected features. This type of plot is particularly useful for identifying outliers and understanding the spread and skewness of the data. In fact, the features were laid out along the x-axis, and their respective values along the y-axis, with boxes representing the interquartile range and whiskers extending to show the range of the data. Outliers were indicated as individual points beyond the whiskers.
Both visualisations are key in EDA as they inform the data pre-processing choices (such as feature scaling or outlier handling) and potential feature engineering that may be necessary before modelling. The boxplot helps to highlight features that have wide variances in their values and may benefit from normalisation or scaling.

Machine Learning Models

The machine learning modelling phase involved preparing the complete dataset, selecting appropriate algorithms, and evaluating their performance. Initially, the target variable was encoded numerically using LabelEncoder() to satisfy the input requirements of the machine learning algorithms and then the dataset was split into training and testing sets with a test size of 20% and a random state for reproducibility. Afterwards, feature scaling was performed using StandardScaler() to standardise the features by removing the mean and scaling to unit variance which is a necessary step for algorithms like Support Vector Machine (SVM) and Logistic Regression (LR). In fact, three different machine learning models were selected for training the predictive analyses: SVM with radial basis function (RBF) kernel, RF, and LR. The SVM and LR models required the scaled feature data, while the RF model used the unscaled data due to its inherent robustness to variable scales.

Model Evaluation

The performance of each model was assessed using classification reports and Matthews Correlation Coefficient (MCC) that is a balanced measure even if the classes are of very different sizes. The classification reports provided detailed insights into precision, recall, and F1-score for each class along with accuracy and weighted averages for the models proposed. Lastly, the trained models and their predictions were again serialised using pickle for future use and were saved along with their predictions and MCC scores, in a file named 'model_data.pkl'. To better aid the visualisation of these analyses, confusion matrices were constructed for the evaluation of the performance of the three machine learning models performances. Each matrix included annotations for the exact proportions and was labelled with axes titles indicating 'True' vs. 'Predicted' outcomes and the titles for each plot such as 'SVM Confusion Matrix', 'RF Confusion Matrix', and 'LR Confusion Matrix' clearly identified the model evaluated.

Model Validation

To validate the performance and robustness of the trained models, k-fold cross-validation was employed. This technique partitions the data into k equally sized segments, or 'folds', and iteratively trains the model k times, each time using one-fold as the test set and the remaining folds as the training set. For instance, a 5-fold cross-validation strategy was chosen to provide a balance between the variance of the model performance estimate and the computational efficiency and cross-validation accuracy scores were computed for each model using the accuracy metric, which represents the proportion of correct predictions over the total number of instances.
Moreover, the mean accuracy and standard deviation for each model's cross-validation were printed, providing an estimate of the model's predictive performance and its variability.
Furthermore, the MCC was chosen as an additional performance metric for cross-validation due to its effectiveness as a balanced measure that can be used even with datasets of imbalanced classes. Finally, to preserve the results for further analysis and potential replication of the study, the cross-validation scores for both accuracy and MCC were compiled into a dictionary and serialised into a pickle file named 'cross_val_results.pkl'.

# Results 

Pre-processing and EDA

The initial data pre-processing steps involved cleaning the dataset by removing rows with missing values, ensuring that no duplicates existed, and encoding categorical variables into numeric representations. The final dataset comprised 602 instances and 211 features, prepared for analyses.

The EDA revealed a moderately imbalanced class distribution with 402 instances of the 'BBB+' class and 203 of the 'BBB-' class (Fig. 1).  

<img width="707" alt="Screenshot 2024-05-22 at 21 43 01" src="https://github.com/francarocci/Computational-Analysis-of-Drug-Compounds-for-Blood-Brain-Barrier-Permeability-Prediction-using-ML/assets/141650033/b3a8fe34-a573-4374-9f97-6124700bdfe6">

PCA of molecular descriptors revealed shows the spread of the data in the reduced dimensional space and the first two principal components accounted for 21.99% and 17.2% of the variance in the dataset, respectively (Fig. 2). The scatter plot visualises these components, where each point represents a molecule, coloured according to its class designation: red for 'BBB+' indicating blood-brain barrier permeability, and blue for 'BBB-' indicating non-permeability.
There is some overlap between the two classes, but there are regions where one class predominates and the first principal component (PC1) does not separate the two classes, but it suggests that while it captures the greatest variance, it is not solely sufficient for classification. Also, the second principal component (PC2) contributes to the separation, although the classes are not distinctly partitioned.

<img width="711" alt="Screenshot 2024-05-22 at 21 43 44" src="https://github.com/francarocci/Computational-Analysis-of-Drug-Compounds-for-Blood-Brain-Barrier-Permeability-Prediction-using-ML/assets/141650033/6a5d70b6-15a7-480e-8bd3-7e42abad0007">

The feature selection process via RFE identified 10 molecular descriptors as the most relevant for predicting blood-brain barrier permeability. This crucial step was employed with a RF to systematically remove the least significant features until the top 10 most relevant features were determined. The algorithm successfully identified 'MinEStateIndex', 'qed', 'MaxPartialCharge', 'MinPartialCharge', 'MinAbsPartialCharge', 'TPSA', 'VSA_EState2', 'VSA_EState3', 'NOCount', and 'NumHeteroatoms' as the most valuable features.

The correlation analysis represented by the heatmap of the 10 most relevant features was created (Fig. 3). The range of correlation coefficients varies from -0.68 to 1.00, with 1.00 indicating a perfect positive correlation (as seen on the diagonal where each feature correlates with itself). Most features show low to moderate correlation with each other, suggesting that the RFE algorithm successfully selected a diverse set of features. Notably, 'MaxPartialCharge' and 'MinAbsPartialCharge' exhibit a very high positive correlation of 0.95, indicating that they may share a significant amount of information, also the 'TPSA' feature shows high positive correlations with 'VSA_EState2' and 'VSA_EState3', with coefficients of 0.93 and 0.82, respectively, suggesting that these descriptors might be capturing related aspects of the molecular structure. On the other hand, negative correlations are also observed, such as between 'MinEStateIndex' and 'MaxPartialCharge' (-0.68), which may reflect inverse relationships in chemical properties.

<img width="698" alt="Screenshot 2024-05-22 at 21 44 26" src="https://github.com/francarocci/Computational-Analysis-of-Drug-Compounds-for-Blood-Brain-Barrier-Permeability-Prediction-using-ML/assets/141650033/14ecd21e-c97e-4fb9-acbe-a48d77c6f04f">

The boxplot provides a visual summary of the distributions and variances for each of the top 10 features crucial to the predictive modelling (Fig. 4). 
For instance, the median of each feature is marked by a line inside the box, and it varies significantly across features, indicating differences in central tendency and the interquartile ranges (IQRs), represented by the boxes, also vary, with features like 'MaxPartialCharge' and 'MinAbsPartialCharge' displaying wider IQRs, suggesting greater variability within those features. Furthermore, some features, such as 'MinEStateIndex', show several outliers, which are indicated by points beyond the whiskers of the boxplot. And finally, the feature 'TPSA' (Topological Polar Surface Area) displays a particularly high range of values, suggesting a diverse set of molecules with respect to their polar characteristics.

<img width="705" alt="Screenshot 2024-05-22 at 21 44 58" src="https://github.com/francarocci/Computational-Analysis-of-Drug-Compounds-for-Blood-Brain-Barrier-Permeability-Prediction-using-ML/assets/141650033/4a107f4b-a33e-4a0d-82f5-d8900194c4dd">

Machine Learning Models

The results from the application of SVM demonstrated high precision 83% and recall 95% for the 'BBB+' class, with a slightly lower recall 61% for the 'BBB-' class, resulting in an F1-score of 88% and 71%, respectively. Its overall accuracy was 84%, indicating a robust ability to correctly classify both permeable and non-permeable compounds.
Lastly, the MCC for the SVM was 0.6206, reflecting a good predictive quality, considering the MCC’s range of -1 to +1.
On the other hand, RF showed better precision 87% for the 'BBB+' class and a commendable recall 93%, achieving an F1-score of 90%, which indicates a strong balance between precision and recall. For the 'BBB-' class, the precision was also high at 83%, with a recall of 73% and an F1-score of 78%. In this case, the accuracy was 86%, higher than the SVM model, and the MCC of 0.6799 suggests that the Random Forest model has a substantial predictive power.
Lastly, in the LR model, the precision 83% and recall 89% for the 'BBB+' class were high, but lower for the 'BBB-' class (precision: 74%, recall: 63%), with corresponding F1-scores of 86% and 68%. The overall accuracy was 80%, which is the lowest among the three models, and the MCC was 0.5445, indicating a moderate predictive quality.

Confusion matrices were constructed for these three models, and each one of them showed different insights (Fig. 5). The SVM one presented with high true positive rate for the 'BBB+' class (0 class) with 95% correctly predicted and the 'BBB-' class (1 class) had a true positive rate of 61%, indicating more false negatives than the 'BBB+' class. Overall, the SVM model shows a strong ability to identify the 'BBB+' class but is less effective for the 'BBB-' class.
On the other side, the RF Confusion Matrix demonstrated a high true positive rate of 93% for the 'BBB+' class, indicating strong predictive performance and the 'BBB-' class had a lower true positive rate at 73%, indicating a relatively higher occurrence of false negatives. In fact, it generally shows good performance across both classes with a slightly better recognition of the 'BBB+' class.
And finally, the LR one shows that the true positive rate for the 'BBB+' class is 89%, which is slightly lower than the RF model but higher than the SVM model, and true positive rate for the 'BBB-' class is 63%. This is comparable to the SVM model but less than the RF model, indicating similar challenges in predicting the 'BBB-' class. As a result, the LR model appears to balance between sensitivity and specificity for both classes.

<img width="720" alt="Screenshot 2024-05-22 at 21 45 32" src="https://github.com/francarocci/Computational-Analysis-of-Drug-Compounds-for-Blood-Brain-Barrier-Permeability-Prediction-using-ML/assets/141650033/c878782c-4bea-4d50-b1b8-08ef0e76fe66">

As the final step of the ML models results, the k-fold cross-validation process was utilised to evaluate the robustness of the SVM, RF, and LR models. SVM achieved a cross-validation accuracy of 81.5%, with a standard deviation of ±1.7%, indicating consistent performance across different folds. The SVM model had a CV MCC of 0.56, with a standard deviation of ±4.5%, suggesting a moderate predictive quality.
On the other hand, the RF model showed a CV accuracy of 80.5% with a higher standard deviation of ±3.3%, reflecting a slight variation in performance across folds. The CV MCC for the RF was 0.542, with a standard deviation of ±8.5%, denoting a reasonable predictive quality with some variability in the MCC across the folds.
Lastly, the LR model recorded a CV accuracy of 76.9%, with a standard deviation of ±2.6%, which was the lowest accuracy among the three models but with also low variability. The CV MCC for LR was 0.482, with a standard deviation of ±4.1%, indicating the weakest predictive quality among the three models.

# Discussion

This comprehensive study elucidated the molecular descriptors prediction of blood-brain barrier permeability and evaluated the performance of several machine learning models. The trajectory included data pre-processing, EDA, feature selection, and rigorous model validation, which facilitated the development of SVM, RF, and LR models.
Initial stages of data pre-processing and EDA revealed a moderate imbalance within the dataset, therefore, RFE was instrumental in identifying ten molecular descriptors integral to predictive modelling. And once the features were selected, the correlation matrix provided an overview of the relationships between descriptors, highlighting the effectiveness of RFE in reducing feature redundancy by revealing significant positive correlations amongst certain descriptors. This analysis was further emphasised by the boxplot results which showed the necessity for feature scaling, particularly when utilising models like SVM that thrive on scaled input data. Notably, the presence of outliers, especially within descriptors such as 'MinEStateIndex', indicated complexities that necessitate robust modelling techniques.
Additionally, a notable PCA offered insights into the dataset's structure, revealing clusters that signified underlying structural differences between permeable and non-permeable compounds. 

Overall, the performances evaluation, adjudicated by confusion matrices, demonstrated a model inclination towards the 'BBB+' class, suggesting a model bias or reflection of the inherent complexity in accurately predicting the 'BBB-' class. In fact, cross-validation results showed SVM as the model par excellence in terms of consistency and predictability, closely followed by RF, while LR was marginally less optimal. High accuracy scores were recorded across all the models; however, the moderate MCC values intimated that, despite being reliable, the models did not excel in differentiating between classes.

The visualisations tools were pivotal during the second phase of the EDA post-feature selection as they informed crucial pre-processing decisions such as scaling or outlier management, possibly preceding any feature modification efforts. These results underscore the strengths and potential areas for improvement within each model. In fact, RF, for instance, showed commendable performance, with confusion matrices offering insights into each model's capacity to accurately classify binary outcomes and facilitating a comparative evaluation of their predictive efficacy.

This validation phase was important for appraising the models' generalisation capabilities, that is an essential aspect of machine learning performance. Moreover, the variability in cross-validation scores provided additional data on model stability across different data subsets, highlighting their robustness even towards imbalanced data.

This study underpins the need for further investigation, potentially incorporating a broader array of molecular descriptors, advanced feature selection techniques, and perhaps oversampling strategies for a more balanced representation of classes. In fact, the consistency in misclassification of specific compounds invites additional scrutiny, potentially augmenting the models with domain-specific knowledge to unravel the underlying complexity of the BBB permeability prediction.

# Conclusion

This study has effectively utilised machine learning techniques to forecast blood-brain barrier permeability, showcasing the potential of SVM and RF models as they have exhibited proficiency in discerning between permeable and non-permeable compounds, despite facing challenges such as class imbalance and the complexity of molecular descriptors. The exploratory data analysis, underscored by PCA and features selection through RFE, played a crucial role in optimising the data pre-processing phase because it highlighted the critical need for feature scaling and careful management of outliers, ensuring that the most relevant molecular descriptors were focused upon to improve the models’ predictive accuracy.

However, the journey does not end here. The promising results achieved by the SVM and RF models open the doors to further exploration and future research is encouraged to delve into more sophisticated ensemble methods and neural network paradigms to navigate the complex patterns present in the data more effectively. For instance, expanding the array of molecular descriptors, employing advanced feature selection techniques, and integrating domain-specific knowledge to address consistent misclassification are potential avenues for enhancing model prediction performance. Furthermore, adopting oversampling strategies might ensure a more balanced class representation, laying a solid foundation for advancing predictive models in cheminformatics and making significant strides in the drug development process for central nervous system drugs.

# References

1.	Ghose AK, et al. A knowledge-based approach in designing combinatorial or medicinal chemistry libraries for drug discovery. 1. A qualitative and quantitative characterization of known drug databases. J Comb Chem. 1999 Jan;1(1):55-68. 

2.	Pajouhesh H, Lenz GR. Medicinal chemical properties of successful central nervous system drugs. NeuroRx. 2005 Oct;2(4):541-53.

3.	Clark DE. In silico prediction of blood-brain barrier permeation. Drug Discov Today. 2003 Oct 15;8(20):927-33.

4.	Singh M, et al. A classification model for blood brain barrier penetration. J Mol Graph Model. 2020 May;96:107516. 
